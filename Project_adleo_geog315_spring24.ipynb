{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlf7TkEq4GLby1VuVQq4vh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paudelsushil/labelcombinations/blob/main/Project_adleo_geog315_spring24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YKuq-IJWkPw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective3:\n",
        "## DeepLab3+ Model"
      ],
      "metadata": {
        "id": "Av8BX6v5mL_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Data Preparation"
      ],
      "metadata": {
        "id": "-byRvwK76QOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ehcJSZG5ad6f",
        "outputId": "3cf6dd34-4a8c-4bac-a4a9-3603f85fae6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install required packages\n",
        "\n",
        "%%capture\n",
        "!pip install rasterio"
      ],
      "metadata": {
        "id": "TB_rgHf166Qg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import tqdm # Adds a smart progress meter to any iterable or file operation\n",
        "\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import cv2\n",
        "import rasterio\n",
        "#  defines a rectangular area within the raster using four properties\n",
        "# xoff, yoff, width, height\n",
        "from rasterio.windows import Window\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "\n",
        "from IPython.core.debugger import set_trace # Insert a breakpoint into the code\n",
        "from IPython.display import Image\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XNc4dQUl7RAQ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining the Dataset for training, validating, and testing the model"
      ],
      "metadata": {
        "id": "rAQQOPVvBqAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "src_dir = \"/content/gdrive/MyDrive/adleo/project_data\"\n",
        "\n",
        "WorkingFolder = \"/content/gdrive/MyDrive/adleo/project_data\"\n"
      ],
      "metadata": {
        "id": "JP0eOJYh9cTx"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Data"
      ],
      "metadata": {
        "id": "ROUZHqtxGnsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_paths = os.listdir(os.path.join(src_dir, \"images\"))\n",
        "lbl_paths = os.listdir(os.path.join(src_dir, \"labels\"))\n",
        "\n",
        "# Check if all paths are valid lists\n",
        "if not all(isinstance(path_list, list) for path_list in (img_paths, lbl_paths)):\n",
        "    raise ValueError(\"Both image_paths and label_paths must be lists.\")\n",
        "\n",
        "print(\"No. of images:\",len(img_paths), \"\\n\", \"No. of labels:\", len(lbl_paths))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MA9ZtQWP93z5",
        "outputId": "a9ba0f86-a61c-49d6-c419-ff2a0227f85b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No. of images: 33874 \n",
            " No. of labels: 33757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3M7m80jMTut",
        "outputId": "cdb02e11-75a5-4edf-9dde-26bfa457a534"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "33874 33757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pre-processing the data for the model"
      ],
      "metadata": {
        "id": "xBHQIHCUCBrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#===============================================================================\n",
        "# Data Loader Function\n",
        "#-------------------------------------------------------------------------------\n",
        "def load_data(data_path, usage=\"train\", window=None, norm_stats_type=None,\n",
        "              is_label=False):\n",
        "    '''\n",
        "    Read geographic data into numpy array\n",
        "    Params:\n",
        "        data_path : str\n",
        "            Path of data to load\n",
        "        usage : str\n",
        "            Usage of the data: \"train\", \"validate\", or \"predict\"\n",
        "        window : tuple\n",
        "            The view onto a rectangular subset of the data, in the format of\n",
        "            (column offsets, row offsets, width in pixel, height in pixel)\n",
        "        norm_stats_type : str\n",
        "            How the normalization statistics is calculated.\n",
        "        is_label : binary\n",
        "            Decide whether to saturate data with tested threshold\n",
        "    Returns:\n",
        "        narray\n",
        "    '''\n",
        "\n",
        "    with rasterio.open(data_path, \"r\") as src:\n",
        "\n",
        "        if is_label:\n",
        "            if src.count != 1:\n",
        "                raise InputError(\"Label shape not applicable: \\\n",
        "                                 expected 1 channel\")\n",
        "            img = src.read(1)\n",
        "        else:\n",
        "            nodata = src.nodata\n",
        "            assert norm_stats_type in [\"local_per_tile\", \"local_per_band\",\n",
        "                                       \"global_per_band\"]\n",
        "            if norm_stats_type == \"local_per_tile\":\n",
        "                img = mmnorm1(src.read(), nodata=nodata)\n",
        "            elif norm_stats_type == \"local_per_band\":\n",
        "                img = mmnorm2(src.read(), nodata=nodata, clip_val=1.5)\n",
        "            elif norm_stats_type == \"global_per_band\":\n",
        "                img = mmnorm3(src.read(), nodata=nodata, clip_val=1.5)\n",
        "\n",
        "            if usage in ['train', 'validate']:\n",
        "               img = img[:, max(0, window[1]): window[1] + window[3],\n",
        "                         max(0, window[0]): window[0] + window[2]]\n",
        "\n",
        "    return img\n",
        "#===============================================================================\n",
        "# Normalization Function\n",
        "#-------------------------------------------------------------------------------\n",
        "def mmnorm1(img, nodata):\n",
        "    '''\n",
        "    Data normalization with min/max method\n",
        "    Params:\n",
        "        img (narray): The targeted image for normalization\n",
        "    Returns:\n",
        "        narrray\n",
        "    '''\n",
        "\n",
        "    img_tmp = np.where(img == nodata, np.nan, img)\n",
        "    img_max = np.nanmax(img_tmp)\n",
        "    img_min = np.nanmin(img_tmp)\n",
        "    normalized = (img - img_min) / (img_max - img_min)\n",
        "    normalized = np.clip(normalized, 0, 1)\n",
        "\n",
        "    return normalized\n",
        "#-------------------------------------------------------------------------------\n",
        "def mmnorm2(img, nodata, clip_val=None):\n",
        "    r\"\"\"\n",
        "    Normalize the input image pixels to [0, 1] ranged based on the\n",
        "    minimum and maximum statistics of each band per tile.\n",
        "    Arguments:\n",
        "            img : numpy array\n",
        "                Stacked image bands with a dimension of (C,H,W).\n",
        "            nodata : str\n",
        "                Value reserved to represent NoData in the image chip.\n",
        "            clip_val : int\n",
        "                Defines how much of the distribution tails to be cut off.\n",
        "    Returns:\n",
        "            img : numpy array\n",
        "                Normalized image stack of size (C,H,W).\n",
        "    Note 1: If clip then min, max are calculated from the clipped image.\n",
        "    \"\"\"\n",
        "\n",
        "    # filter out zero pixels in generating statistics.\n",
        "    nan_corr_img = np.where(img == nodata, np.nan, img)\n",
        "    nan_corr_img = np.where(img == 0, np.nan, img)\n",
        "\n",
        "    if clip_val > 0:\n",
        "        left_tail_clip = np.nanpercentile(nan_corr_img, clip_val)\n",
        "        right_tail_clip = np.nanpercentile(nan_corr_img, 100 - clip_val)\n",
        "\n",
        "        left_clipped_img = np.where(img < left_tail_clip, left_tail_clip, img)\n",
        "        clipped_img = np.where(left_clipped_img > right_tail_clip,\n",
        "                               right_tail_clip, left_clipped_img)\n",
        "\n",
        "        normalized_bands = []\n",
        "        for i in range(img.shape[0]):\n",
        "            band_min = np.nanmin(clipped_img[i, :, :])\n",
        "            band_max = np.nanmax(clipped_img[i, :, :])\n",
        "            normalized_band = (clipped_img[i, :, :] - band_min) /\\\n",
        "                (band_max - band_min)\n",
        "            normalized_bands.append(np.expand_dims(normalized_band, 0))\n",
        "        normal_img = np.concatenate(normalized_bands, 0)\n",
        "\n",
        "    elif clip_val == 0 or clip_val is None:\n",
        "        normalized_bands = []\n",
        "        for i in range(img.shape[0]):\n",
        "            band_min = np.nanmin(nan_corr_img[i, :, :])\n",
        "            band_max = np.nanmax(nan_corr_img[i, :, :])\n",
        "            normalized_band = (nan_corr_img[i, :, :] - band_min) /\\\n",
        "                (band_max - band_min)\n",
        "            normalized_bands.append(np.expand_dims(normalized_band, 0))\n",
        "        normal_img = np.concatenate(normalized_bands, 0)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"clip must be a non-negative decimal.\")\n",
        "\n",
        "    normal_img = np.clip(normal_img, 0, 1)\n",
        "    return normal_img\n",
        "#------------------------------------------------------------------------------\n",
        "def mmnorm3(img, nodata, clip_val=None):\n",
        "    hardcoded_stats = {\n",
        "        \"mins\": np.array([331.0, 581.0, 560.0, 1696.0]),\n",
        "        \"maxs\": np.array([1403.0, 1638.0, 2076.0, 3652.0])\n",
        "    }\n",
        "\n",
        "    num_bands = img.shape[0]\n",
        "    mins = hardcoded_stats[\"mins\"]\n",
        "    maxs = hardcoded_stats[\"maxs\"]\n",
        "\n",
        "    if clip_val:\n",
        "        normalized_bands = []\n",
        "        for i in range(num_bands):\n",
        "            nan_corr_img = np.where(img[i, :, :] == nodata, np.nan,\n",
        "                                    img[i, :, :])\n",
        "            nan_corr_img = np.where(img[i, :, :] == 0, np.nan, img[i, :, :])\n",
        "            left_tail_clip = np.nanpercentile(nan_corr_img, clip_val)\n",
        "            right_tail_clip = np.nanpercentile(nan_corr_img, 100 - clip_val)\n",
        "            left_clipped_band = np.where(img[i, :, :] < left_tail_clip,\n",
        "                                         left_tail_clip, img[i, :, :])\n",
        "            clipped_band = np.where(left_clipped_band > right_tail_clip,\n",
        "                                    right_tail_clip, left_clipped_band)\n",
        "            normalized_band = (clipped_band - mins[i]) / (maxs[i] - mins[i])\n",
        "            normalized_bands.append(np.expand_dims(normalized_band, 0))\n",
        "        img = np.concatenate(normalized_bands, 0)\n",
        "\n",
        "    else:\n",
        "        for i in range(num_bands):\n",
        "            img[i, :, :] = (img[i, :, :] - mins[i]) / (maxs[i] - mins[i])\n",
        "\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img\n",
        "#------------------------------------------------------------------------------\n",
        "# Input Error method for Error handling message\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "class InputError(Exception):\n",
        "    '''\n",
        "    Exception raised for errors in the input\n",
        "    '''\n",
        "\n",
        "    def __init__(self, message):\n",
        "        '''\n",
        "        Params:\n",
        "            message (str): explanation of the error\n",
        "\n",
        "        '''\n",
        "\n",
        "        self.message = message\n",
        "\n",
        "    def __str__(self):\n",
        "        '''\n",
        "        Define message to return when error is raised\n",
        "        '''\n",
        "\n",
        "        if self.message:\n",
        "            return 'InputError, {} '.format(self.message)\n",
        "        else:\n",
        "            return 'InputError'"
      ],
      "metadata": {
        "id": "2XeJgyr294ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utility Functions"
      ],
      "metadata": {
        "id": "aHlnUrwXGCf6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SjT_uj9kGGVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Normalization"
      ],
      "metadata": {
        "id": "upnS_NL-Cfoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_normalize_image(image, dtype=np.float32):\n",
        "    \"\"\"\n",
        "    image_path(str) : Absolute path to the image patch.\n",
        "    dtype (numpy datatype) : data type of the normalized image default is\n",
        "    \"np.float32\".\n",
        "    \"\"\"\n",
        "\n",
        "    # Calculate the minimum and maximum values for each band\n",
        "    min_values = np.nanmin(image, axis=(1, 2))[:, np.newaxis, np.newaxis]\n",
        "    max_values = np.nanmax(image, axis=(1, 2))[:, np.newaxis, np.newaxis]\n",
        "\n",
        "    # Normalize the image data to the range [0, 1]\n",
        "    normalized_img = (image - min_values) / (max_values - min_values)\n",
        "\n",
        "    # Return the normalized image data\n",
        "    return normalized_img"
      ],
      "metadata": {
        "id": "cGI_pLF0Ce6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Augmentation"
      ],
      "metadata": {
        "id": "tj_af9t_Cr_p"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lFJyV0MyCMe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Building\n",
        "Deeplab3+ based on [Chen et al., 2024](https://link.springer.com/content/pdf/10.1007/s40747-023-01304-z.pdf)\n"
      ],
      "metadata": {
        "id": "93Q9eXHW94ng"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iv7azLGq97cB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}