{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "2gPlnmtdnrMq",
        "7CqzUOXlqDFx",
        "WOyXkiy83PtA",
        "RXbd5uV02NzN"
      ],
      "authorship_tag": "ABX9TyMrxy4rAYIGxDY+5YQmoBLc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paudelsushil/labelcombinations/blob/main/Project_adleo_geog315_spring24.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective3:\n",
        "# DeepLab3+ Model\n",
        "DeepLabv3+ utilizes an encoder-decoder structure to perform image segmentation. The encoder extracts shallow and high-level semantic information from the image, while the decoder combines low-level and high-level features to improve the accuracy of segmentation boundaries and classify the semantic information of different pixels [Chen et al., (2018)](https://link.springer.com/content/pdf/10.1007/978-3-030-01234-2_49.pdf?pdf=inline%20link).\n",
        "\n",
        "This project is based on the improved classis DeepLabv3+ network model proposed by [Chen et al.,(2023)](https://link.springer.com/content/pdf/10.1007/s40747-023-01304-z.pdf).\n",
        "\n",
        "## Architecture of improved DeepLabv3+ with MobileNetv2 backbone\n",
        "\n",
        "**`A. Encoder`**\n",
        " 1. `Backbone` : lightweight network `MobileNetv2` in place of Xception.\n",
        " 2. `ASPP` : `Hybrid Dialted Convolution` (HDC) module to alleviate the gridding effect. In addition,  `Strip Pooling Module` is used instead of spatial mean pooling to improve th elocal segmentation effect.\n",
        " 3. `Normalization-based Attention Module` (NAM): This lightweight attention mechanism is also applied to the stacked compressed high-level feature maps to help improve the segmentation accuracy of the image.\n",
        "\n",
        "**`B. Decoder`**\n",
        "1. `NAM`: The seventh layer feature with `NAM` attention is upsampled to the same size as the fourth layer feature after fusion and channel adjustment.\n",
        "2. `ResNet50`: This module is added to obtain riccher low-level target feature information.\n",
        "3. `Concatenate`: The **deep features** and **shallow features** are concatenated as in the original model.\n",
        "4. `Upsampling`: After a 3 X 3 convolution and 4 X `upsampling`, the image is restored to its original size.\n",
        "\n",
        "\n",
        " [Architecture Image]()"
      ],
      "metadata": {
        "id": "Av8BX6v5mL_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EA7jiYXqe4DZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Mount the Drive"
      ],
      "metadata": {
        "id": "-byRvwK76QOk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ehcJSZG5ad6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "446b35fa-54a9-4461-b7d5-b5e3d975d551"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Install reqiured libraries"
      ],
      "metadata": {
        "id": "mTBINaaxgtzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install rasterio\n"
      ],
      "metadata": {
        "id": "TB_rgHf166Qg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Import necessary libraries"
      ],
      "metadata": {
        "id": "XtxW_6cigzHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required packages\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from datetime import datetime, timedelta\n",
        "import tqdm # Adds a smart progress meter to any iterable or file operation\n",
        "\n",
        "import math\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import cv2\n",
        "import rasterio\n",
        "#  defines a rectangular area within the raster using four properties\n",
        "# xoff, yoff, width, height\n",
        "from rasterio.windows import Window\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "from torch.utils.tensorboard.writer import SummaryWriter\n",
        "\n",
        "\n",
        "import logging\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import itertools\n",
        "\n",
        "\n",
        "from IPython.core.debugger import set_trace # Insert a breakpoint into the code\n",
        "from IPython.display import Image\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XNc4dQUl7RAQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Utility Functions\n"
      ],
      "metadata": {
        "id": "4FzjUpiAg00A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Error Handling Method"
      ],
      "metadata": {
        "id": "oaaHtfwSgFRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InputError(Exception):\n",
        "    '''\n",
        "    Exception raised for errors in the input\n",
        "    '''\n",
        "    def __init__(self, message):\n",
        "        '''\n",
        "        Params:\n",
        "            message (str): explanation of the error\n",
        "        '''\n",
        "        self.message = message\n",
        "    def __str__(self):\n",
        "        '''\n",
        "        Define message to return when error is raised\n",
        "        '''\n",
        "        if self.message:\n",
        "            return 'InputError, {} '.format(self.message)\n",
        "        else:\n",
        "            return 'InputError'"
      ],
      "metadata": {
        "id": "x02_B-UTgDsv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Data Loading and Normalization"
      ],
      "metadata": {
        "id": "nkziXksMhbL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading\n",
        "# =============================================================================\n",
        "def load_data(data_path, usage=\"train\", window=None, norm_stats_type=None,\n",
        "              is_label=False):\n",
        "    '''\n",
        "    Read geographic data into numpy array\n",
        "    Params:\n",
        "        data_path : str\n",
        "            Path of data to load\n",
        "        usage : str\n",
        "            Usage of the data: \"train\", \"validate\", or \"predict\"\n",
        "        window : tuple\n",
        "            The view onto a rectangular subset of the data, in the format of\n",
        "            (column offsets, row offsets, width in pixel, height in pixel)\n",
        "        norm_stats_type : str\n",
        "            How the normalization statistics is calculated.\n",
        "        is_label : binary\n",
        "            Decide whether to saturate data with tested threshold\n",
        "    Returns:\n",
        "        narray\n",
        "    '''\n",
        "\n",
        "    with rasterio.open(data_path, \"r\") as src:\n",
        "\n",
        "        if is_label:\n",
        "            if src.count != 1:\n",
        "                raise InputError(\"Label shape not applicable: \\\n",
        "                                 expected 1 channel\")\n",
        "            img = src.read(1)\n",
        "        else:\n",
        "            nodata = src.nodata\n",
        "            assert norm_stats_type in [\"local_per_tile\", \"local_per_band\",\n",
        "                                       \"global_per_band\"]\n",
        "            if norm_stats_type == \"local_per_tile\":\n",
        "                img = mmnorm1(src.read(), nodata=nodata)\n",
        "            elif norm_stats_type == \"local_per_band\":\n",
        "                img = mmnorm2(src.read(), nodata=nodata, clip_val=1.5)\n",
        "            elif norm_stats_type == \"global_per_band\":\n",
        "                img = mmnorm3(src.read(), nodata=nodata, clip_val=1.5)\n",
        "            else:\n",
        "                raise InputError(\"Invalid normalization type\")\n",
        "\n",
        "        if usage in ['train', 'validate'] and window is not None:\n",
        "          img = img[:, max(0, window[1]): window[1] + window[3], \\\n",
        "                    max(0, window[0]): window[0] + window[2]]\n",
        "\n",
        "    return img\n",
        "\n",
        "# ==============================================================================\n",
        "# Load and stack multiple geographic data (images) into numpy array\n",
        "def get_stacked_img(img_paths, usage, norm_stats_type=\"local_per_tile\",\n",
        "                    window=None):\n",
        "    '''\n",
        "    Read geographic data into numpy array\n",
        "    Params:\n",
        "        gsPath :str\n",
        "            Path of growing season image\n",
        "        osPath : str\n",
        "            Path of off season image\n",
        "        img_paths : list\n",
        "            List of paths for imgages\n",
        "        usage : str\n",
        "            Usage of the image: \"train\", \"validate\", or \"predict\"\n",
        "        norm_stats_type : str\n",
        "            How the normalization statistics is calculated.\n",
        "        window : tuple\n",
        "            The view onto a rectangular subset of the data, in the\n",
        "            format of (column offsets, row offsets, width in pixel, height in\n",
        "            pixel)\n",
        "    Returns:\n",
        "        ndarray\n",
        "    '''\n",
        "\n",
        "    if len(img_paths) > 1:  # If there are multiple image paths:\n",
        "      img_ls = [load_data(m, usage, window, norm_stats_type) for m in img_paths]\n",
        "      # Load data for each image path, potentially applying normalization\n",
        "      img = np.concatenate(img_ls, axis=0).transpose(1, 2, 0)\n",
        "      # Combine the loaded data into a single array and rearrange dimensions\n",
        "    else:  # If there's only a single image path:\n",
        "      # Load data for the single image path and rearrange dimensions\n",
        "      img = load_data(img_paths[0], usage, \\\n",
        "                      window, norm_stats_type).transpose(1, 2, 0)\n",
        "\n",
        "    # For 'train' or 'validate' subsets:\n",
        "    if usage in [\"train\", \"validate\"] and window is not None:\n",
        "      # Extract window parameters\n",
        "      col_off, row_off, col_target, row_target = window\n",
        "      row, col, c = img.shape  # Get image dimensions\n",
        "\n",
        "      # Check if image is smaller than the target window\n",
        "      if row < row_target or col < col_target:\n",
        "          row_off = abs(row_off) if row_off < 0 else 0  # Adjust offsets\n",
        "          col_off = abs(col_off) if col_off < 0 else 0\n",
        "\n",
        "          # Create a larger blank canvas\n",
        "          canvas = np.zeros((row_target, col_target, c))\n",
        "          # Place image onto canvas\n",
        "          canvas[row_off: row_off + row, col_off : col_off + col, :] = img\n",
        "          return canvas  # Return the canvas with the padded image\n",
        "\n",
        "      else:\n",
        "          return img  # The image fits the window, so return it directly\n",
        "\n",
        "    elif usage == \"predict\":  # For prediction purposes:\n",
        "      return img  # Return the image as is\n",
        "\n",
        "    else:\n",
        "      raise ValueError  # Invalid 'usage' value\n",
        "# ==============================================================================\n",
        "# Methods to normalize image data using Min-Max values\n",
        "def mmnorm1(img, nodata):\n",
        "    '''\n",
        "    Data normalization with min/max method\n",
        "    Params:\n",
        "        img (narray): The targeted image for normalization\n",
        "    Returns:\n",
        "        narrray\n",
        "    '''\n",
        "\n",
        "    img_tmp = np.where(img == nodata, np.nan, img)\n",
        "    img_max = np.nanmax(img_tmp)\n",
        "    img_min = np.nanmin(img_tmp)\n",
        "    normalized = (img - img_min) / (img_max - img_min)\n",
        "    normalized = np.clip(normalized, 0, 1)\n",
        "\n",
        "    return normalized\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Methods to normalize image data using Min-Max values\n",
        "def mmnorm2(img, nodata, clip_val=None):\n",
        "    \"\"\"\n",
        "    Normalize the input image pixels to [0, 1] ranged based on the\n",
        "    minimum and maximum statistics of each band per tile.\n",
        "    Arguments:\n",
        "            img : numpy array\n",
        "                Stacked image bands with a dimension of (C,H,W).\n",
        "            nodata : str\n",
        "                Value reserved to represent NoData in the image chip.\n",
        "            clip_val : int\n",
        "                Defines how much of the distribution tails to be cut off.\n",
        "    Returns:\n",
        "            img : numpy array\n",
        "                Normalized image stack of size (C,H,W).\n",
        "    Note 1: If clip then min, max are calculated from the clipped image.\n",
        "    \"\"\"\n",
        "    # filter out zero pixels in generating statistics.\n",
        "    nan_corr_img = np.where(img == nodata, np.nan, img)\n",
        "    nan_corr_img = np.where(img == 0, np.nan, img)\n",
        "    if clip_val is not None and clip_val > 0:\n",
        "        left_tail_clip = np.nanpercentile(nan_corr_img, clip_val)\n",
        "        right_tail_clip = np.nanpercentile(nan_corr_img, 100 - clip_val)\n",
        "        left_clipped_img = np.where(img < left_tail_clip, left_tail_clip, img)\n",
        "        clipped_img = np.where(left_clipped_img > right_tail_clip,\\\n",
        "                               right_tail_clip, left_clipped_img)\n",
        "        normalized_bands = []\n",
        "        for i in range(img.shape[0]):\n",
        "            band_min = np.nanmin(clipped_img[i, :, :])\n",
        "            band_max = np.nanmax(clipped_img[i, :, :])\n",
        "            normalized_band = (clipped_img[i, :, :] - band_min) / (band_max - band_min)\n",
        "            normalized_bands.append(np.expand_dims(normalized_band, 0))\n",
        "        normal_img = np.concatenate(normalized_bands, 0)\n",
        "    elif clip_val == 0 or clip_val is None:\n",
        "        normalized_bands = []\n",
        "        for i in range(img.shape[0]):\n",
        "            band_min = np.nanmin(nan_corr_img[i, :, :])\n",
        "            band_max = np.nanmax(nan_corr_img[i, :, :])\n",
        "            normalized_band = (nan_corr_img[i, :, :] - band_min) / (band_max - band_min)\n",
        "            normalized_bands.append(np.expand_dims(normalized_band, 0))\n",
        "        normal_img = np.concatenate(normalized_bands, 0)\n",
        "    else:\n",
        "        raise ValueError(\"clip must be a non-negative decimal.\")\n",
        "    normal_img = np.clip(normal_img, 0, 1)\n",
        "    return normal_img\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Methods to normalize image data using pre-defined Min-Max values for each layer\n",
        "def mmnorm3(img, nodata, clip_val=None):\n",
        "    hardcoded_stats = {\n",
        "        \"mins\": np.array([331.0, 581.0, 560.0, 1696.0]),\n",
        "        \"maxs\": np.array([1403.0, 1638.0, 2076.0, 3652.0]) }\n",
        "    num_bands = img.shape[0]\n",
        "    mins = hardcoded_stats[\"mins\"]\n",
        "    maxs = hardcoded_stats[\"maxs\"]\n",
        "    if clip_val:\n",
        "        normalized_bands = []\n",
        "        for i in range(num_bands):\n",
        "            nan_corr_img = np.where(img[i, :, :] == nodata, np.nan,\n",
        "                                    img[i, :, :])\n",
        "            nan_corr_img = np.where(img[i, :, :] == 0, np.nan, img[i, :, :])\n",
        "            left_tail_clip = np.nanpercentile(nan_corr_img, clip_val)\n",
        "            right_tail_clip = np.nanpercentile(nan_corr_img, 100 - clip_val)\n",
        "            left_clipped_band = np.where(img[i, :, :] < left_tail_clip,\n",
        "                                         left_tail_clip, img[i, :, :])\n",
        "            clipped_band = np.where(left_clipped_band > right_tail_clip,\n",
        "                                    right_tail_clip, left_clipped_band)\n",
        "            normalized_band = (clipped_band - mins[i]) / (maxs[i] - mins[i])\n",
        "            normalized_bands.append(np.expand_dims(normalized_band, 0))\n",
        "        img = np.concatenate(normalized_bands, 0)\n",
        "    else:\n",
        "        for i in range(num_bands):\n",
        "            img[i, :, :] = (img[i, :, :] - mins[i]) / (maxs[i] - mins[i])\n",
        "    img = np.clip(img, 0, 1)\n",
        "    return img\n",
        "# ------------------------------------------------------------------------------\n",
        "def min_max_normalize_image(image, dtype=np.float32):\n",
        "    \"\"\"\n",
        "    image_path(str) : Absolute path to the image patch.\n",
        "    dtype (numpy datatype) : data type of the normalized image default is\n",
        "    \"np.float32\".\n",
        "    \"\"\"\n",
        "    # Calculate the minimum and maximum values for each band\n",
        "    min_values = np.nanmin(image, axis=(1, 2))[:, np.newaxis, np.newaxis]\n",
        "    max_values = np.nanmax(image, axis=(1, 2))[:, np.newaxis, np.newaxis]\n",
        "    # Normalize the image data to the range [0, 1]\n",
        "    normalized_img = (image - min_values) / (max_values - min_values)\n",
        "    # Return the normalized image data\n",
        "    return normalized_img"
      ],
      "metadata": {
        "id": "7aXBJ3ALg0bW"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Image Processing"
      ],
      "metadata": {
        "id": "B51n6nfQjzL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to get buffered window to align and destination images\n",
        "def get_buffered_window(src_path, dst_path, buffer):\n",
        "    '''\n",
        "    Get bounding box representing subset of source image that overlaps with\n",
        "    bufferred destination image, in format of (column offsets, row offsets,\n",
        "    width, height)\n",
        "    Params:\n",
        "        src_path : str\n",
        "            Path of source image to get subset bounding box\n",
        "        dst_path : str\n",
        "            Path of destination image as a reference to define the\n",
        "            bounding box. Size of the bounding box is\n",
        "            (destination width + buffer * 2, destination height + buffer * 2)\n",
        "        buffer :int\n",
        "            Buffer distance of bounding box edges to destination image\n",
        "            measured by pixel numbers\n",
        "    Returns:\n",
        "        tuple in form of (column offsets, row offsets, width, height)\n",
        "    '''\n",
        "    with rasterio.open(src_path, \"r\") as src:\n",
        "        gt_src = src.transform\n",
        "\n",
        "    with rasterio.open(dst_path, \"r\") as dst:\n",
        "        gt_dst = dst.transform\n",
        "        w_dst = dst.width\n",
        "        h_dst = dst.height\n",
        "    col_off = round((gt_dst[2] - gt_src[2]) / gt_src[0]) - buffer\n",
        "    row_off = round((gt_dst[5] - gt_src[5]) / gt_src[4]) - buffer\n",
        "    width = w_dst + buffer * 2\n",
        "    height = h_dst + buffer * 2\n",
        "\n",
        "    return col_off, row_off, width, height\n",
        "# ------------------------------------------------------------------------------\n",
        "# Method to get metadata of a specified image  while applying a buffer method\n",
        "def get_meta_from_bounds(file, buffer):\n",
        "    '''\n",
        "    Get metadata of unbuffered region in given file\n",
        "    Params:\n",
        "        file (str):  File name of a image chip\n",
        "        buffer (int): Buffer distance measured by pixel numbers\n",
        "    Returns:\n",
        "        dictionary\n",
        "    '''\n",
        "    with rasterio.open(file, \"r\") as src:\n",
        "        meta = src.meta\n",
        "        dst_width = src.width - 2 * buffer\n",
        "        dst_height = src.height - 2 * buffer\n",
        "        if buffer is not None:\n",
        "          window = Window(buffer, buffer, dst_width, dst_height)\n",
        "\n",
        "          win_transform = src.window_transform(window)\n",
        "          meta.update({\n",
        "            'width': dst_width,\n",
        "            'height': dst_height,\n",
        "            'transform': win_transform,\n",
        "            'count': 1,\n",
        "            'nodata': -128,\n",
        "            'dtype': 'int8' })\n",
        "        else:\n",
        "          pass\n",
        "\n",
        "    return meta\n",
        "# ------------------------------------------------------------------------------\n",
        "# Method to generate image chips from a large image data\n",
        "def get_chips(img, dsize, buffer):\n",
        "    '''\n",
        "    Generate small chips from input images and the corresponding index of each\n",
        "    chip The index marks the location of corresponding upper-left pixel of a\n",
        "    chip.\n",
        "    Params:\n",
        "        img (narray): Image in format of (H,W,C) to be crop, in this case it is\n",
        "            the concatenated image of growing season and off season\n",
        "        dsize (int): Cropped chip size\n",
        "        buffer (int):Number of overlapping pixels when extracting images chips\n",
        "    Returns:\n",
        "        list of cropped chips and corresponding coordinates\n",
        "    '''\n",
        "    h, w, _ = img.shape\n",
        "    x_ls = range(0,h - 2 * buffer, dsize - 2 * buffer)\n",
        "    y_ls = range(0, w - 2 * buffer, dsize - 2 * buffer)\n",
        "    index = list(itertools.product(x_ls, y_ls))\n",
        "    img_ls = []\n",
        "    for i in range(len(index)):\n",
        "        x, y = index[i]\n",
        "        img_ls.append(img[x:x + dsize, y:y + dsize, :])\n",
        "\n",
        "    return img_ls, index"
      ],
      "metadata": {
        "id": "ByCNbnvCiHE4"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Image data visualization"
      ],
      "metadata": {
        "id": "3ILLosRilyy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to vizualize a histogram of image data distribution\n",
        "def display_hist(img):\n",
        "    '''\n",
        "    Display data distribution of input image in a histogram\n",
        "    Params:\n",
        "        img (narray): Image in form of (H,W,C) to display data distribution\n",
        "    '''\n",
        "    img = mmnorm1(img)\n",
        "    im = np.where(img == 0, np.nan, img)\n",
        "    plt.hist(img.ravel(), 500, [np.nanmin(im), img.max()])\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.show()\n",
        "# ------------------------------------------------------------------------------\n",
        "# Method to generate color composite based on the season\n",
        "def comp432_dis(img, season):\n",
        "    '''\n",
        "    Generate false color composites\n",
        "    Params:\n",
        "        img (torch.tensor): Image in format of (C,H,W)\n",
        "        season (str): Season of the composite to generate, be  \"GS\" or \"OS\"\n",
        "    '''\n",
        "    viewsize = img.shape[1:]\n",
        "    if season == \"GS\":\n",
        "        b4 = mmnorm1(img[3, :, :].cpu().view(1, *viewsize),0)\n",
        "        b3 = mmnorm1(img[2, :, :].cpu().view(1, *viewsize),0)\n",
        "        b2 = mmnorm1(img[1, :, :].cpu().view(1, *viewsize),0)\n",
        "    elif season == \"OS\":\n",
        "        b4 = mmnorm1(img[7, :, :].cpu().view(1, *viewsize), 0)\n",
        "        b3 = mmnorm1(img[6, :, :].cpu().view(1, *viewsize), 0)\n",
        "        b2 = mmnorm1(img[5, :, :].cpu().view(1, *viewsize), 0)\n",
        "    else:\n",
        "        raise ValueError(\"Bad season value\")\n",
        "    img = torch.cat([b4, b3, b2], 0)\n",
        "    return img\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Method to visualize composites and labels\n",
        "def display(img, label, mask):\n",
        "\n",
        "    '''\n",
        "    Display composites and their labels\n",
        "    Params:\n",
        "        img (torch.tensor): Image in format of (C,H,W)\n",
        "        label (torch.tensor): Label in format of (H,W)\n",
        "        mask (torch.tensor): Mask in format of (H,W)\n",
        "    '''\n",
        "    gsimg = (comp432_dis(img, \"GS\") * 255).permute(1, 2, 0).int()\n",
        "    osimg = (comp432_dis(img, \"OS\") * 255).permute(1, 2, 0).int()\n",
        "\n",
        "    _, figs = plt.subplots(1, 4, figsize=(20, 20))\n",
        "\n",
        "    label = label.cpu()\n",
        "\n",
        "    figs[0].imshow(gsimg)\n",
        "    figs[1].imshow(osimg)\n",
        "    figs[2].imshow(label)\n",
        "    figs[3].imshow(mask)\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mOA7XXhKl56r"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 Reproducibile, progress report, and Logs"
      ],
      "metadata": {
        "id": "2gPlnmtdnrMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to make all the randomization processes start from a shared seed.\n",
        "def make_reproducible(seed=42, cudnn=True):\n",
        "    \"\"\"Make all the randomization processes start from a shared seed\"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.random.manual_seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    if cudnn:\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "# ------------------------------------------------------------------------------\n",
        "def progress_reporter(msg, verbose, logger=None):\n",
        "    \"\"\"Helps control print statements and log writes\n",
        "    Parameters\n",
        "    ----------\n",
        "    msg : str\n",
        "      Message to write out\n",
        "    verbose : bool\n",
        "      Prints or not to console\n",
        "    logger : logging.logger\n",
        "      logger (defaults to none)\n",
        "    Returns:\n",
        "    --------\n",
        "        Message to console and or log\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(msg)\n",
        "    if logger:\n",
        "        logger.info(msg)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Method to create a logger\n",
        "def setup_logger(log_dir, log_name, use_date=False):\n",
        "    \"\"\"Create logger\n",
        "    \"\"\"\n",
        "    if use_date:\n",
        "        dt = datetime.now().strftime(\"%d%m%Y_%H%M\")\n",
        "        log = \"{}/{}_{}.log\".format(log_dir, log_name, dt)\n",
        "    else:\n",
        "        log = \"{}/{}.log\".format(log_dir, log_name)\n",
        "\n",
        "    for handler in logging.root.handlers[:]:\n",
        "        logging.root.removeHandler(handler)\n",
        "    log_format = (\n",
        "        f\"%(asctime)s::%(levelname)s::%(name)s::%(filename)s::\"\n",
        "        f\"%(lineno)d::%(message)s\"\n",
        "    )\n",
        "    logging.basicConfig(filename=log, filemode='w',\n",
        "                        level=logging.INFO, format=log_format)\n",
        "\n",
        "    return logging.getLogger()\n"
      ],
      "metadata": {
        "id": "PBEg1GfQno8N"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.6 Pickle Serialization"
      ],
      "metadata": {
        "id": "7CqzUOXlqDFx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to save a dataset object as a serialized file\n",
        "def pickle_dataset(dataset, file_path):\n",
        "    with open(file_path, \"wb\") as fp:\n",
        "        pickle.dump(dataset, fp)\n",
        "\n",
        "# Method to load a dataset object from a serialized file\n",
        "def load_pickle(file_path):\n",
        "    return pd.read_pickle(file_path)"
      ],
      "metadata": {
        "id": "b2NL6-K-oItn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Data Preparation\n",
        "1. Find the suitable `image dataset` to apply `improved DeepLabv3+ model` for the image segmentation process.\n",
        "  - For this task, we used image dataset that was used in `S. Khallaghi, (2024) ch. 2`.\n",
        "2. Prepare the `labels (pixel-wise annotations)` that are compatible with selected image dataset.\n",
        "  - For this task, we filtered [all_class_cataloge](/content/gdrive/MyDrive/adleo/project_data/label_catalog_allclasses.csv) using methods and functions given in [notebook](https://github.com/paudelsushil/labelcombinations/blob/main/Make_Labels_ADLEO_Final.ipynb) and prepared final [filtered cataloge](/content/gdrive/MyDrive/adleo/project_data/label-catalog-filtered.csv) to get our pixel-wise annotations as a [lable images](/content/gdrive/MyDrive/adleo/project_data/labels).\n"
      ],
      "metadata": {
        "id": "pzxo77ik_UJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Check for GPU availability"
      ],
      "metadata": {
        "id": "RYdcyrBDtUcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5.1 Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tirz3g1JIeAr",
        "outputId": "b1162e76-d157-4c23-f6fa-53cc37cc99af"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5.2 Image Augmentation\n",
        "\n"
      ],
      "metadata": {
        "id": "xBHQIHCUCBrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to Applies horizontal or vertical flip augmentation\n",
        "# to an image patch and label\n",
        "def flip_image_and_label(image, label, flip_type):\n",
        "    \"\"\"\n",
        "    Applies horizontal or vertical flip augmentation to an image patch and label\n",
        "\n",
        "    Args:\n",
        "        image (numpy array) : The input image patch as a numpy array.\n",
        "        label (numpy array) : The corresponding label as a numpy array.\n",
        "        flip_type (string) : Based on the direction of flip. Can be either\n",
        "            'hflip' or 'vflip'.\n",
        "    Returns:\n",
        "        A tuple containing the flipped image patch and label as numpy arrays.\n",
        "    \"\"\"\n",
        "    if flip_type == 'hflip':\n",
        "        # Apply horizontal flip augmentation to the image patch\n",
        "        flipped_image = cv2.flip(image, 1)\n",
        "        # Apply horizontal flip augmentation to the label\n",
        "        flipped_label = cv2.flip(label, 1)\n",
        "    elif flip_type == 'vflip':\n",
        "        # Apply vertical flip augmentation to the image patch\n",
        "        flipped_image = cv2.flip(image, 0)\n",
        "        # Apply vertical flip augmentation to the label\n",
        "        flipped_label = cv2.flip(label, 0)\n",
        "    else:\n",
        "        raise ValueError(\"Flip direction must be 'horizontal' or 'vertical'.\")\n",
        "    # Return the flipped image patch and label as a tuple\n",
        "    return flipped_image.copy(), flipped_label.copy()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Method  to apply rotation augmentation to an image patch and label.\n",
        "def rotate_image_and_label(image, label, angle):\n",
        "    \"\"\"\n",
        "    Applies rotation augmentation to an image patch and label.\n",
        "    Args:\n",
        "        image (numpy array) : The input image patch as a numpy array.\n",
        "        label (numpy array) : The corresponding label as a numpy array.\n",
        "        angle (lost of floats) : If the list has exactly two elements they will\n",
        "            be considered the lower and upper bounds for the rotation angle\n",
        "            (in degrees) respectively. If number of elements are bigger than 2,\n",
        "            then one value is chosen randomly as the roatation angle.\n",
        "    Returns:\n",
        "        A tuple containing the rotated image patch and label as numpy arrays.\n",
        "    \"\"\"\n",
        "    if isinstance(angle, tuple) or isinstance(angle, list):\n",
        "        if len(angle) == 2:\n",
        "            rotation_degree = random.uniform(angle[0], angle[1])\n",
        "        elif len(angle) > 2:\n",
        "            rotation_degree = random.choice(angle)\n",
        "        else:\n",
        "            raise ValueError(\"Parameter degree needs at least two elements.\")\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Rotation bound param for augmentation must be a tuple or list.\"\n",
        "        )\n",
        "    # Define the center of the image patch\n",
        "    center = tuple(np.array(label.shape)/2.0)\n",
        "    # Define the rotation matrix\n",
        "    rotation_matrix = cv2.getRotationMatrix2D(center, rotation_degree, 1.0)\n",
        "    # Apply rotation augmentation to the image patch\n",
        "    rotated_image = cv2.warpAffine(image, rotation_matrix, image.shape[:2],\n",
        "                                   flags=cv2.INTER_LINEAR)\n",
        "    # Apply rotation augmentation to the label\n",
        "    rotated_label = cv2.warpAffine(label, rotation_matrix, label.shape[:2],\n",
        "                                   flags=cv2.INTER_NEAREST)\n",
        "    # Return the rotated image patch and label as a tuple\n",
        "    return rotated_image.copy(), np.rint(rotated_label.copy())"
      ],
      "metadata": {
        "id": "SjT_uj9kGGVJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.3 Image patch generator"
      ],
      "metadata": {
        "id": "upnS_NL-Cfoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to generate index to divide the scene into small chips\n",
        "def patch_center_index(cropping_ref, patch_size, overlap, usage,\n",
        "                       positive_class_threshold=None, verbose=True):\n",
        "    \"\"\"\n",
        "    Generate index to divide the scene into small chips.\n",
        "    Each index marks the location of corresponding chip center.\n",
        "    Arguments:\n",
        "        cropping_ref (list) : Reference raster layers, to be used to generate\n",
        "            the index. In our case, it is study area binary mask and label mask.\n",
        "        patch_size (int) : Size of each clipped patches.\n",
        "        overlap (int) : amount of overlap between the extracted chips.\n",
        "        usage (str) : Either 'train', 'val'. Chipping strategy is different for\n",
        "            different usage.\n",
        "        positive_class_threshold (float) : A real value as a threshold for the\n",
        "            proportion of positive class to the total areal of the chip. Used to\n",
        "            decide if the chip should be considered as a positive chip in the\n",
        "            sampling process.\n",
        "    verbose (binary) : If set to True prints on screen the detailed list of\n",
        "            center coordinates of the sampled chips.\n",
        "    Returns:\n",
        "        proportional_patch_index : A list of index recording the center of\n",
        "        patches to extract from the input\n",
        "    \"\"\"\n",
        "    assert usage in [\"train\", \"validation\", \"inference\"]\n",
        "\n",
        "    if usage == \"inference\":\n",
        "        mask = cropping_ref\n",
        "    else:\n",
        "        mask, label = cropping_ref\n",
        "\n",
        "    half_size = patch_size // 2\n",
        "    step_size = patch_size - 2 * overlap\n",
        "\n",
        "    proportional_patch_index = []\n",
        "    non_proportional_patch_index = []\n",
        "    neg_patch_index = []\n",
        "    # Get the index of all the non-zero elements in the mask.\n",
        "    x = np.argwhere(mask)\n",
        "    # First col of x shows the row indices (height) of the mask layer\n",
        "    # (iterate over the y axis or latitude).\n",
        "    x_min = min(x[:, 0]) + half_size\n",
        "    x_max = max(x[:, 0]) - half_size\n",
        "    # Second col of x shows the column indices (width) of the mask layer\n",
        "    # (iterate over the x axis or longitude).\n",
        "    y_min = min(x[:, 1]) + half_size\n",
        "    y_max = max(x[:, 1]) - half_size\n",
        "    # Generate index for the center of each patch considering the proportion of\n",
        "    # each category falling into each patch.\n",
        "    for j in range(y_min, y_max + 1, step_size):\n",
        "\n",
        "        for i in range(x_min, x_max + 1, step_size):\n",
        "            # Split the mask and label layers into patches based on the index of\n",
        "            # the center of the patch\n",
        "            mask_ref = mask[i - half_size: i + half_size,\n",
        "                            j - half_size: j + half_size]\n",
        "            if usage != \"inference\":\n",
        "                label_ref = label[i - half_size: i + half_size,\n",
        "                                  j - half_size: j + half_size]\n",
        "\n",
        "            if (usage == \"train\") and mask_ref.all():\n",
        "\n",
        "                if label_ref.any() != 0:\n",
        "                    pond_ratio = np.sum(label_ref == 1) / label_ref.size\n",
        "                    if pond_ratio >= positive_class_threshold:\n",
        "                        proportional_patch_index.append([i, j])\n",
        "                else:\n",
        "                    neg_patch_index.append([i, j])\n",
        "\n",
        "            if (usage == \"validation\") and (label_ref.any() != 0) \\\n",
        "                and mask_ref.all():\n",
        "                non_proportional_patch_index.append([i, j])\n",
        "\n",
        "            if (usage == \"inference\") and (mask_ref.any() != 0):\n",
        "                non_proportional_patch_index.append([i, j])\n",
        "\n",
        "    if usage == \"train\":\n",
        "\n",
        "        num_negative_samples = min(\n",
        "            math.ceil(0.2 * len(proportional_patch_index)), 15\n",
        "        )\n",
        "        neg_samples = random.sample(neg_patch_index, num_negative_samples)\n",
        "\n",
        "        proportional_patch_index.extend(neg_samples)\n",
        "\n",
        "    # For test set use the indices generated from mask without\n",
        "    # considering the class proportions.\n",
        "    if usage in [\"validation\", \"inference\"]:\n",
        "        proportional_patch_index = non_proportional_patch_index\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Number of patches:\", len(proportional_patch_index))\n",
        "        print(\"Patched from:\\n{}\".format(proportional_patch_index))\n",
        "\n",
        "    return proportional_patch_index"
      ],
      "metadata": {
        "id": "cGI_pLF0Ce6Z"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 Active dataset loading method\n"
      ],
      "metadata": {
        "id": "nYZ6dLjEqZvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class datasetloader(Dataset):\n",
        "    def __init__(self, src_dir, usage, dataset_name=None,\n",
        "                 transform=None, norm_stats_type=\"local_per_tile\",\n",
        "                 patch_size=None, overlap=None, catalog_index=None,\n",
        "                 buffer=None):\n",
        "        \"\"\"\n",
        "        src_dir (str or path): Root of resource directory.\n",
        "        dataset_name (str): Name of the training/validation dataset containing\n",
        "                              structured folders for image, label\n",
        "        usage (str): Either 'train' or 'validation'.\n",
        "        transform (list): Each element is string name of the transformation to\n",
        "            be used.\n",
        "        \"\"\"\n",
        "        # Initialize dataset parameters\n",
        "        self.src_dir = src_dir\n",
        "        self.dataset_name = dataset_name\n",
        "        self.transform = transform\n",
        "        self.norm_stats_type = norm_stats_type\n",
        "        self.patch_size = patch_size\n",
        "        self.overlap = overlap\n",
        "        self.usage = usage\n",
        "\n",
        "        # Ensure that the usage is one of the expected options\n",
        "        assert self.usage in [\"train\", \"validation\", \"inference\"], \"Usage is not recognized.\"\n",
        "\n",
        "        if self.usage in [\"train\", \"validation\"]:\n",
        "            # For training or validation, set up image and label directories\n",
        "            assert self.dataset_name is not None\n",
        "            img_dir = Path(src_dir) / self.dataset_name / self.usage / \"bands\"\n",
        "            img_fnames = [\n",
        "                Path(dirpath) / f\n",
        "                for dirpath, _, filenames in os.walk(img_dir)\n",
        "                for f in filenames if f.endswith(\".tif\")\n",
        "            ]\n",
        "            img_fnames.sort()\n",
        "\n",
        "            lbl_dir = Path(src_dir) / self.dataset_name / self.usage / \"labels\"\n",
        "            lbl_fnames = [\n",
        "                Path(dirpath) / f\n",
        "                for dirpath, _, filenames in os.walk(lbl_dir)\n",
        "                for f in filenames if f.endswith(\".tif\")\n",
        "            ]\n",
        "            lbl_fnames.sort()\n",
        "\n",
        "            # Load all image and label chips\n",
        "            self.img_chips = []\n",
        "            self.lbl_chips = []\n",
        "\n",
        "            for img_path, lbl_path in tqdm.tqdm(zip(img_fnames, lbl_fnames),\n",
        "                                                total=len(img_fnames)):\n",
        "                # Load and normalize image chips based on the provided normalization stats\n",
        "                img_chip = load_data(img_path, usage=self.usage, norm_stats_type=self.norm_stats_type, is_label=False)\n",
        "                img_chip = img_chip.transpose((1, 2, 0))\n",
        "\n",
        "                # Load label chips\n",
        "                lbl_chip = load_data(lbl_path, usage=self.usage, is_label=True)\n",
        "\n",
        "                # Append to the lists\n",
        "                self.img_chips.append(img_chip)\n",
        "                self.lbl_chips.append(lbl_chip)\n",
        "\n",
        "            print(f\"Loaded {len(self.img_chips)} image chips\")\n",
        "            print(f\"Loaded {len(self.lbl_chips)} label chips\")\n",
        "\n",
        "        else:\n",
        "            # For inference, read the catalog for metadata\n",
        "            assert self.csv_name is not None\n",
        "\n",
        "            # Load the catalog and select the relevant row\n",
        "            catalog = pd.read_csv(os.path.join(self.src_dir, self.csv_name))\n",
        "            self.catalog = catalog.iloc[catalog_index]\n",
        "\n",
        "            # Extract image and mask paths from the catalog\n",
        "            self.tile = (self.catalog[\"wrs_path\"], self.catalog[\"wrs_row\"])\n",
        "            img_path_ls = [self.catalog[\"img_dir\"]]\n",
        "            mask_path_ls = [self.catalog[\"mask_dir\"]]\n",
        "\n",
        "            # Get metadata for the selected image\n",
        "            self.meta = get_meta_from_bounds(Path(src_dir) / img_path_ls[0], buffer = None)\n",
        "\n",
        "            # Define the half size of patches for indexing\n",
        "            half_size = self.patch_size // 2\n",
        "\n",
        "            self.img_chips = []\n",
        "            self.coor = []\n",
        "\n",
        "            for img_path, mask_path in zip(img_path_ls, mask_path_ls):\n",
        "                # Load and normalize image chips\n",
        "                img = load_data(os.path.join(self.src_dir, img_path), usage=self.usage, norm_stats_type=self.norm_stats_type, is_label=False)\n",
        "                img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "                # Load the mask data for indexing\n",
        "                mask = load_data(os.path.join(self.src_dir, mask_path), usage=self.usage, is_label=True)\n",
        "\n",
        "                # Generate indices based on the mask and patch size\n",
        "                index = patch_center_index(mask, self.patch_size, self.overlap, self.usage)\n",
        "\n",
        "                for i in range(len(index)):\n",
        "                    x = index[i][0]\n",
        "                    y = index[i][1]\n",
        "\n",
        "                    # Extract and store each image patch based on the indices\n",
        "                    self.img_chips.append(img[x - half_size: x + half_size, y - half_size: y + half_size, :])\n",
        "                    self.coor.append([x, y])\n",
        "\n",
        "            print(f\"Loaded {len(self.img_chips)} image patches\")\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the total number of samples in the dataset.\"\"\"\n",
        "        return len(self.img_chips)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \"\"\"Return the sample at the given index, ensuring it's valid.\"\"\"\n",
        "        if self.usage in [\"train\", \"validation\"]:\n",
        "            image_chip = self.img_chips[index]\n",
        "            label_chip = self.lbl_chips[index]\n",
        "\n",
        "            # Check if the chips are valid\n",
        "            if image_chip is None or image_chip.size == 0 or label_chip is None or label_chip.size == 0:\n",
        "                return None\n",
        "\n",
        "            if self.usage == \"train\" and self.transform:\n",
        "                # Apply transformations if applicable\n",
        "                trans_flip_ls = [m for m in self.transform if \"flip\" in m]\n",
        "                if random.randint(0, 1) and len(trans_flip_ls) > 1:\n",
        "                    trans_flip = random.sample(trans_flip_ls, 1)[0]\n",
        "                    image_chip, label_chip = flip_image_and_label(image_chip, label_chip, trans_flip)\n",
        "\n",
        "                if random.randint(0, 1) and \"rotate\" in self.transform:\n",
        "                    image_chip, label_chip = rotate_image_and_label(image_chip, label_chip, angle=[0, 90])\n",
        "\n",
        "            # Convert numpy arrays to torch tensors\n",
        "            image_tensor = torch.from_numpy(image_chip.transpose((2, 0, 1))).float()\n",
        "            label_tensor = torch.from_numpy(np.ascontiguousarray(label_chip)).long()\n",
        "\n",
        "            return image_tensor, label_tensor\n",
        "        else:\n",
        "            # For inference, return image chips and coordinates\n",
        "            coor = self.coor[index]\n",
        "            img_chip = self.img_chips[index]\n",
        "\n",
        "            if img_chip is None or img_chip.size == 0:\n",
        "                return None\n",
        "\n",
        "            image_tensor = torch.from_numpy(img_chip.transpose((2, 0, 1))).float()\n",
        "            return image_tensor, coor\n",
        ""
      ],
      "metadata": {
        "id": "gsOtrByjOzof"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Collate method for dataloader"
      ],
      "metadata": {
        "id": "nwd2z9bRy7hZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collate method for dataloader to handle \"None\" batches\n",
        "def collate(batch):\n",
        "  \"\"\"\n",
        "  Collate function for dataloader.\n",
        "  \"\"\"\n",
        "  batch = list(filter(lambda x: x is not None, batch))\n",
        "  return torch.utils.data.dataloader.default_collate(batch)"
      ],
      "metadata": {
        "id": "H8L9w_hJy64h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Model Building\n"
      ],
      "metadata": {
        "id": "93Q9eXHW94ng"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.1 Basic Convolutional Neural blocks"
      ],
      "metadata": {
        "id": "4kPEb5Il4vru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv1x1_bn_relu(nn.Module):\n",
        "    def __init__(self, inch, outch, stride = 1, padding = 0, dilation = 1,\\\n",
        "                 groups = 1, relu = True):\n",
        "        super(Conv1x1_bn_relu, self).__init__()\n",
        "        self.applyRelu = relu\n",
        "        self.conv = nn.Sequential(nn.Conv2d(inch, outch, 1, stride = stride,\\\n",
        "                                            padding = padding, \\\n",
        "                                            dilation = dilation,\n",
        "                                            groups = groups),\n",
        "                                  nn.BatchNorm2d(outch))\n",
        "\n",
        "        if self.applyRelu:\n",
        "            self.relu = nn.ReLU(True)\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x.clone())\n",
        "        if self.applyRelu:\n",
        "            x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "class Conv3x3_bn_relu(nn.Module):\n",
        "    def __init__(self, inch, outch, padding = 0, stride =1, dilation = 1, \\\n",
        "                 groups = 1, relu = True):\n",
        "        super(Conv3x3_bn_relu, self).__init__()\n",
        "        self.applyRelu = relu\n",
        "\n",
        "        self.conv = nn.Sequential(nn.Conv2d(inch, outch, 3, \\\n",
        "                                            padding = padding, stride = stride,\\\n",
        "                                            dilation = dilation,\n",
        "                                            groups = groups),\n",
        "                                  nn.BatchNorm2d(outch))\n",
        "        if self.applyRelu:\n",
        "            self.relu = nn.ReLU(True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        if self.applyRelu:\n",
        "            out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "RRCFc0kN4hUt"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.2 Model Backbone\n",
        "ResNet101"
      ],
      "metadata": {
        "id": "L30w4P_51fyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "block_num = {\"resnet101\": [3, 4, 23, 3]}\n",
        "dilations_by_outStride = {\n",
        "    16: [1, 1, 1, 2],\n",
        "    8: [1, 1, 2,4]\n",
        "}\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, block, inch, outStride, layers, firstKernel=7, firstStride=2, firstPadding=3):\n",
        "        super(Resnet, self).__init__()\n",
        "\n",
        "        dilations = dilations_by_outStride[outStride]\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(inch, 64, firstKernel, stride=firstStride, padding=firstPadding), \\\n",
        "                                   nn.BatchNorm2d(64), \\\n",
        "                                   nn.ReLU(True)) # 1/2\n",
        "\n",
        "        # # 7x7 conv to three 3x3 conv\n",
        "        # layer0 = []\n",
        "        # for i in range(ceil(firstKernel/3.0)):\n",
        "        #     if i == 0:\n",
        "        #         layer0.append(Conv3x3_bn_relu(inch, 64, padding = 1, stride = firstStride))\n",
        "        #     else:\n",
        "        #         layer0.append(Conv3x3_bn_relu(64, 64, padding = 1))\n",
        "        # self.conv1 = nn.Sequential(*layer0)\n",
        "\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, padding=0) # original\n",
        "        # self.pool1 = nn.MaxPool2d(2, stride=2, padding=0)\n",
        "\n",
        "        self.stage1 = self.makeStage(block, 64, 1, layers[0], dilation = dilations[0], firstStage=True, ) # 1/4\n",
        "        self.stage2 = self.makeStage(block, 128, 2, layers[1], dilation = dilations[1])  # 1/8\n",
        "        self.stage3 = self.makeStage(block, 256, 2, layers[2], dilation = dilations[2])  # 1/16\n",
        "        self.stage4 = self.makeStage(block, 512, 1, layers[3], dilation = dilations[3]) # 1/16\n",
        "\n",
        "        # for m in self.modules():\n",
        "        #     if isinstance(m, nn.Conv2d):\n",
        "        #         nn.init.kaiming_normal_(m.weight, mode = \"fan_out\", nonlinearity = \"relu\")\n",
        "        # m.bias.data.fill_(0)\n",
        "\n",
        "    def makeStage(self, block, transch, firstStride, blocks, dilation, firstStage=False):\n",
        "        layers = []\n",
        "\n",
        "        # expansion = 1/4 for basicblock/bottleneck\n",
        "        outch = int(transch * block.expansion) # 64*4=256\n",
        "\n",
        "        if firstStage:\n",
        "            inch = transch  # 64\n",
        "        else:\n",
        "            inch = int(transch * block.expansion / 2)\n",
        "\n",
        "        # dilation setting\n",
        "        # if dilation is None:\n",
        "        #     dilations = [1]*blocks\n",
        "        # else:\n",
        "        #     if len(dilation) != blocks:\n",
        "        #         raise ValueError('Expect dilations to have length {}'.format(blocks))\n",
        "\n",
        "        for i in range(blocks):\n",
        "            if i == 0:\n",
        "                conv = block(inch, outch, dilation = dilation, firstStride=firstStride)\n",
        "            else:\n",
        "                conv = block(outch, outch, dilation = dilation)\n",
        "            layers.append(conv)\n",
        "\n",
        "        return (nn.Sequential(*layers))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pool1(x)\n",
        "        x0 = self.stage1(x) # 128\n",
        "        x = self.stage2(x0) # 64\n",
        "        x = self.stage3(x) #32\n",
        "        x = self.stage4(x)\n",
        "\n",
        "        return x0, x\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "class bottleNeck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, inch, outch, dilation = 1, firstStride = 1, groups = 1, \\\n",
        "                 base_width = 64):\n",
        "        super(bottleNeck, self).__init__()\n",
        "\n",
        "        self.firstBlock = (inch != outch)\n",
        "        transch = int(outch / (self.expansion * groups * base_width / 64))\n",
        "\n",
        "        # downsample in first 1x1 convolution\n",
        "        if self.firstBlock:\n",
        "            self.conv0 = Conv1x1_bn_relu(inch, outch, stride=firstStride, \\\n",
        "                                         relu=False)\n",
        "\n",
        "        # 1x1 conv\n",
        "        self.conv1 = Conv1x1_bn_relu(inch, transch, stride=firstStride)\n",
        "        # 3x3 conv\n",
        "        self.conv2 = Conv3x3_bn_relu(transch, transch, padding = dilation,\\\n",
        "                                     dilation = dilation, groups = groups)\n",
        "        # 1x1 conv\n",
        "        self.conv3 = Conv1x1_bn_relu(transch, outch, relu=False)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        res = self.conv1(x)\n",
        "        res = self.conv2(res)\n",
        "        res = self.conv3(res)\n",
        "\n",
        "        if self.firstBlock:\n",
        "            x = self.conv0(x)\n",
        "\n",
        "        out = self.relu(res + x)\n",
        "        return out\n",
        "# ------------------------------------------------------------------------------\n",
        "class resnet101(nn.Module):\n",
        "    def __init__(self, inch, outStride):\n",
        "        super(resnet101, self).__init__()\n",
        "        self.resnet = Resnet(bottleNeck, inch, outStride, layers=block_num[\"resnet101\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "TK38aBmE2chr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.3 Model **ASSP**"
      ],
      "metadata": {
        "id": "WOyXkiy83PtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ASPP(nn.Module):\n",
        "    def __init__(self, inch, rates, stagech):\n",
        "        super(ASPP, self).__init__()\n",
        "        '''\n",
        "        This class generates the ASPP module introduced in\n",
        "        DeepLabv3: https://arxiv.org/pdf/1706.05587.pdf, which\n",
        "         concatenates 4 parallel atrous spatial pyramid pooling and the image\n",
        "         level features. For more detailed information, please refer to the\n",
        "         paper of DeepLabv3\n",
        "\n",
        "         Args:\n",
        "            inch -- (int) Depth of the input tensor\n",
        "            rates -- (list) A list of rates of the parallel atrous convolution,\n",
        "                     including that for the 1x1 convolution\n",
        "            stagech -- (int) Depth of output tensor for each of the parallel\n",
        "                    atrous convolution\n",
        "\n",
        "         Returns:\n",
        "            A tensor after a 1x1 convolution of the concatenated ASPP features\n",
        "        '''\n",
        "        super(ASPP, self).__init__()\n",
        "        # create stages\n",
        "        self.rates = rates\n",
        "        self.inch = inch\n",
        "        self.stagech = stagech\n",
        "\n",
        "        self.stages = self.makeStages()\n",
        "        # global feature\n",
        "        self.globe = nn.Sequential(nn.AdaptiveAvgPool2d((1,1)), \\\n",
        "                                   Conv1x1_bn_relu(inch, stagech, relu = False))\n",
        "        # self.conv1x1 = Conv1x1_bn_relu(inch, stagech, relu = False)\n",
        "        # self.conv = Conv3x3_bn_relu(inch * 2, inch, padding = 1)\n",
        "        self.conv = Conv1x1_bn_relu(stagech*(len(rates) + 1), stagech,\\\n",
        "                                    relu = False)\n",
        "\n",
        "    def makeStages(self):\n",
        "        outch = self.stagech\n",
        "        inch = self.inch\n",
        "        stages = []\n",
        "        for rate in self.rates:\n",
        "            if rate == 1:\n",
        "                stage = Conv1x1_bn_relu(inch, outch, relu = False)\n",
        "\n",
        "            else:\n",
        "                stage = Conv3x3_bn_relu(inch, outch, padding =rate,\\\n",
        "                                        dilation = rate, relu = False)\n",
        "            stages.append(stage)\n",
        "        return nn.ModuleList(stages)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        # x1 = [F.interpolate(stage(x), size=x_size[-2:], mode=\"bilinear\",\n",
        "        #  align_corners=True) for stage in self.stages]\n",
        "        x0 = [stage(x) for stage in self.stages]\n",
        "\n",
        "        # global feature\n",
        "        x1 = self.globe(x)\n",
        "        x1 = F.interpolate(x1, size = x_size[-2:], mode = \"bilinear\",\\\n",
        "                           align_corners = True)\n",
        "\n",
        "        x = torch.cat(x0 + [x1], 1)\n",
        "        x = self.conv(x)\n",
        "\n",
        "        return x\n",
        ""
      ],
      "metadata": {
        "id": "9lnNno-W3PKV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.4 DeepLabv3plus\n",
        "DeepLabV3+ using ResNet101 as a model backbone"
      ],
      "metadata": {
        "id": "RXbd5uV02NzN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASPPInchByBackbone = {\"resnet\": 2048}\n",
        "quaterOutchByBackbone = {\"resnet\": 256}\n",
        "\n",
        "class deeplab3plus2(nn.Module):\n",
        "    def __init__(self, inch, classNum, backbone = resnet101, outStride = 16,\n",
        "                 rates = [1, 6, 12, 18]):\n",
        "        super(deeplab3plus2, self).__init__()\n",
        "\n",
        "        # backbone\n",
        "        self.backbone = backbone(inch, outStride = outStride)\n",
        "\n",
        "        # ASPP\n",
        "        ASPPinch = ASPPInchByBackbone[backbone.__name__.rstrip('0123456789')]\n",
        "        ASPPoutch = ASPPinch // 8\n",
        "        self.ASPP = ASPP(ASPPinch, rates=rates, stagech=ASPPoutch)\n",
        "\n",
        "        # decoder\n",
        "        quaterOutch = quaterOutchByBackbone[backbone.__name__.rstrip('0123456789')]\n",
        "        self.conv0 = Conv1x1_bn_relu(quaterOutch, ASPPoutch) # 1/4 of origin\n",
        "        self.up1 = nn.ConvTranspose2d(256, 256, 6, stride=4, padding=1)\n",
        "        self.last_conv = nn.Sequential(Conv3x3_bn_relu(ASPPoutch*2, 256, 1),\n",
        "                                       Conv3x3_bn_relu(256, 256, 1),\n",
        "                                       nn.Conv2d(256, classNum, 1))\n",
        "        self.up2 = nn.ConvTranspose2d(classNum, classNum, 6, stride=4, padding=1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x0, x = self.backbone(x)\n",
        "        x = self.ASPP(x)\n",
        "\n",
        "        # decoder\n",
        "        x0 = self.conv0(x0)\n",
        "        x = self.up1(x)\n",
        "        x = torch.cat([x, x0], 1)\n",
        "        x = self.last_conv(x)\n",
        "        x = self.up2(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "dZvth-oN2NU6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7 Model Training and Evaluation\n",
        "## 7.1 Hyperparameter and Dataset Initialization"
      ],
      "metadata": {
        "id": "z-WQVyvi8eZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the hyperparameters\n",
        "batch_size = 16\n",
        "num_epochs = 1\n",
        "initial_lr = 0.001\n",
        "num_classes = 2\n",
        "data_dir = \"/content/gdrive/MyDrive/adleo/assignment5/A5_resources\"\n",
        "WorkingFolder = \"/content/gdrive/MyDrive/adleo/adleo_project_test\"\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Create the training and validation datasets using the `datasetloader`\n",
        "# class with appropriate parameters\n",
        "train_dataset = datasetloader(\n",
        "    src_dir=data_dir,\n",
        "    usage=\"train\",\n",
        "    dataset_name=\"Global\",\n",
        "    transform=[\"hflip\", \"vflip\", \"rotate\"],\n",
        "    patch_size=256,\n",
        "    overlap=64\n",
        ")\n",
        "\n",
        "val_dataset = datasetloader(\n",
        "    src_dir=data_dir,\n",
        "    usage=\"validation\",\n",
        "    dataset_name=\"Global\",\n",
        "    patch_size=256,\n",
        "    overlap=64\n",
        ")\n",
        "\n",
        "# Load datasets using DataLoader for training and validation\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2NvHigN828E",
        "outputId": "1e5e901a-6687-4900-c37d-207b487f086b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1188 image chips\n",
            "Loaded 1188 label chips\n",
            "Loaded 239 image chips\n",
            "Loaded 239 label chips\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.2 Model Initialization and Configuration"
      ],
      "metadata": {
        "id": "7fyClsnsROrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the ResUNet model\n",
        "model = deeplab3plus2(inch=6,  classNum=num_classes)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
        "\n",
        "# Define the learning rate scheduler\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.9)\n",
        "\n",
        "# Determine device availability (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb2eFAk-RXKu",
        "outputId": "e853d4dc-dcbb-4c18-b92c-9179ccbc85a9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "deeplab3plus2(\n",
              "  (backbone): resnet101(\n",
              "    (resnet): Resnet(\n",
              "      (conv1): Sequential(\n",
              "        (0): Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "      )\n",
              "      (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (stage1): Sequential(\n",
              "        (0): bottleNeck(\n",
              "          (conv0): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (stage2): Sequential(\n",
              "        (0): bottleNeck(\n",
              "          (conv0): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2))\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (3): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (stage3): Sequential(\n",
              "        (0): bottleNeck(\n",
              "          (conv0): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(2, 2))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (3): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (4): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (5): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (6): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (7): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (8): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (9): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (10): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (11): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (12): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (13): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (14): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (15): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (16): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (17): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (18): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (19): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (20): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (21): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (22): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "      (stage4): Sequential(\n",
              "        (0): bottleNeck(\n",
              "          (conv0): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (1): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "        (2): bottleNeck(\n",
              "          (conv1): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv2): Conv3x3_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
              "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "            (relu): ReLU(inplace=True)\n",
              "          )\n",
              "          (conv3): Conv1x1_bn_relu(\n",
              "            (conv): Sequential(\n",
              "              (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            )\n",
              "          )\n",
              "          (relu): ReLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (ASPP): ASPP(\n",
              "    (stages): ModuleList(\n",
              "      (0): Conv1x1_bn_relu(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): Conv3x3_bn_relu(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (2): Conv3x3_bn_relu(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (3): Conv3x3_bn_relu(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (globe): Sequential(\n",
              "      (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "      (1): Conv1x1_bn_relu(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv): Conv1x1_bn_relu(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv0): Conv1x1_bn_relu(\n",
              "    (conv): Sequential(\n",
              "      (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (relu): ReLU(inplace=True)\n",
              "  )\n",
              "  (up1): ConvTranspose2d(256, 256, kernel_size=(6, 6), stride=(4, 4), padding=(1, 1))\n",
              "  (last_conv): Sequential(\n",
              "    (0): Conv3x3_bn_relu(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): Conv3x3_bn_relu(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Conv2d(256, 2, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (up2): ConvTranspose2d(2, 2, kernel_size=(6, 6), stride=(4, 4), padding=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.3 Methods for Training and Validation"
      ],
      "metadata": {
        "id": "YWl6sP5eR6AM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method to train the model\n",
        "# Function to train the model\n",
        "def train(train_loader, model, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "    return running_loss / len(train_loader)\n",
        "\n",
        "# Function to validate the model\n",
        "def validate(val_loader, model, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "    return running_loss / len(val_loader)"
      ],
      "metadata": {
        "id": "L42xn_9oSGue"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4 Method for Epoch Iterator"
      ],
      "metadata": {
        "id": "1o9oM7QkSTkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epochIterater(trainData, valData, model, criterion, WorkingFolder,\n",
        "                  initial_lr, num_epochs):\n",
        "    \"\"\"\n",
        "    Epoch iteration for train and evaluation.\n",
        "\n",
        "    Arguments:\n",
        "    trainData (dataloader object): Batch grouped data to train the model.\n",
        "    evalData (dataloader object): Batch grouped data to evaluate the model.\n",
        "    model (pytorch.nn.module object): initialized model.\n",
        "    initial_lr(float): The initial learning rate.\n",
        "    num_epochs (int): User-defined number of epochs to run the model.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    train_loss = []\n",
        "    val_loss = []\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if device.type == \"cuda\":\n",
        "        print('----------GPU available----------')\n",
        "        model = model.to(device)\n",
        "    else:\n",
        "        print('----------No GPU available, using CPU instead----------')\n",
        "        model = model\n",
        "\n",
        "    writer = SummaryWriter(WorkingFolder)\n",
        "    optimizer = optim.Adam(model.parameters(),\n",
        "                           lr=initial_lr,\n",
        "                           betas=(0.9, 0.999),\n",
        "                           eps=1e-08,\n",
        "                           weight_decay=5e-4,\n",
        "                           amsgrad=False)\n",
        "\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
        "                                          step_size=3,\n",
        "                                          gamma=0.90)\n",
        "    start_epoch = datetime.now()\n",
        "    for t in range(num_epochs):\n",
        "        print(\"Epoch [{}/{}]\".format(t + 1, num_epochs))\n",
        "\n",
        "        train(trainData, model, optimizer, criterion, device,\n",
        "              train_loss=train_loss)\n",
        "        validate(valData, model, criterion, device, val_loss=val_loss)\n",
        "\n",
        "        scheduler.step()\n",
        "        print(\"LR: {}\".format(scheduler.get_last_lr()))\n",
        "\n",
        "        writer.add_scalars(\"Loss\",\n",
        "                           {\"train loss\": train_loss[t],\n",
        "                            \"validation loss\": val_loss[t]},\n",
        "                           t + 1)\n",
        "\n",
        "    writer.close()\n",
        "\n",
        "    duration_epoch = datetime.now() - start_epoch\n",
        "    duration_format = str(timedelta(seconds=duration_epoch.seconds))\n",
        "    print(\"--------------- Training finished in {} ---------------\"\\\n",
        "          .format(duration_format))"
      ],
      "metadata": {
        "id": "CoT02jC2Sl_X"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.5 Evaluator Class"
      ],
      "metadata": {
        "id": "1kivBcJWSz7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluator:\n",
        "    \"\"\"Evaluator class for computing accuracy and IoU metrics on a segmentation model.\"\"\"\n",
        "\n",
        "    def __init__(self, num_class):\n",
        "        \"\"\"Initialize the evaluator with the specified number of classes.\n",
        "\n",
        "        Args:\n",
        "            num_class (int): Number of classes for the segmentation task.\n",
        "        \"\"\"\n",
        "        self.num_class = num_class\n",
        "        # Initialize a confusion matrix for tracking class-wise predictions\n",
        "        self.confusion_matrix = np.zeros((self.num_class,) * 2)\n",
        "\n",
        "    def Pixel_Accuracy(self):\n",
        "        \"\"\"Compute the overall pixel accuracy.\n",
        "\n",
        "        Returns:\n",
        "            float: The proportion of correctly classified pixels.\n",
        "        \"\"\"\n",
        "        Acc = np.diag(self.confusion_matrix).sum() / self.confusion_matrix.sum()\n",
        "        return Acc\n",
        "\n",
        "    def Pixel_Accuracy_Class(self):\n",
        "        \"\"\"Compute the pixel accuracy per class.\n",
        "\n",
        "        Returns:\n",
        "            float: The mean pixel accuracy across all classes.\n",
        "        \"\"\"\n",
        "        Acc = np.diag(self.confusion_matrix) / self.confusion_matrix.sum(axis=1)\n",
        "        Acc = np.nanmean(Acc)\n",
        "        return Acc\n",
        "\n",
        "    def Mean_Intersection_over_Union(self):\n",
        "        \"\"\"Compute the mean Intersection over Union (IoU) across all classes.\n",
        "\n",
        "        Returns:\n",
        "            float: The mean IoU value.\n",
        "        \"\"\"\n",
        "        MIoU = np.diag(self.confusion_matrix) / (\n",
        "            np.sum(self.confusion_matrix, axis=1) +\n",
        "            np.sum(self.confusion_matrix, axis=0) -\n",
        "            np.diag(self.confusion_matrix))\n",
        "        MIoU = np.nanmean(MIoU)\n",
        "        return MIoU\n",
        "\n",
        "    def Frequency_Weighted_Intersection_over_Union(self):\n",
        "        \"\"\"Compute the frequency-weighted IoU metric.\n",
        "\n",
        "        Returns:\n",
        "            float: The frequency-weighted IoU value.\n",
        "        \"\"\"\n",
        "        freq = np.sum(self.confusion_matrix, axis=1) / np.sum(self.confusion_matrix)\n",
        "        iu = np.diag(self.confusion_matrix) / (\n",
        "            np.sum(self.confusion_matrix, axis=1) +\n",
        "            np.sum(self.confusion_matrix, axis=0) -\n",
        "            np.diag(self.confusion_matrix))\n",
        "\n",
        "        FWIoU = (freq[freq > 0] * iu[freq > 0]).sum()\n",
        "        return FWIoU\n",
        "\n",
        "    def _generate_matrix(self, gt_image, pre_image):\n",
        "        \"\"\"Generate a confusion matrix given the ground truth and predicted images.\n",
        "\n",
        "        Args:\n",
        "            gt_image (np.array): Ground truth labels.\n",
        "            pre_image (np.array): Predicted labels.\n",
        "\n",
        "        Returns:\n",
        "            np.array: A confusion matrix.\n",
        "        \"\"\"\n",
        "        mask = (gt_image >= 0) & (gt_image < self.num_class)\n",
        "        label = self.num_class * gt_image[mask].astype('int') + pre_image[mask]\n",
        "        count = np.bincount(label, minlength=self.num_class**2)\n",
        "        confusion_matrix = count.reshape(self.num_class, self.num_class)\n",
        "        return confusion_matrix\n",
        "\n",
        "    def add_batch(self, gt_image, pre_image):\n",
        "        \"\"\"Accumulate confusion matrix values from a batch of predictions.\n",
        "\n",
        "        Args:\n",
        "            gt_image (np.array): Ground truth labels.\n",
        "            pre_image (np.array): Predicted labels.\n",
        "        \"\"\"\n",
        "        assert gt_image.shape == pre_image.shape\n",
        "        self.confusion_matrix += self._generate_matrix(gt_image, pre_image)\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset the confusion matrix to zero.\"\"\"\n",
        "        self.confusion_matrix = np.zeros((self.num_class,) * 2)\n"
      ],
      "metadata": {
        "id": "6NTFy_gXS3Bk"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.6 Method for model Evaluation"
      ],
      "metadata": {
        "id": "mM1CYFzbTBKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_accuracy_evaluation(model, dataloader, num_classes):\n",
        "    \"\"\"Evaluate the segmentation model on the given dataset.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The segmentation model.\n",
        "        dataloader (torch.utils.data.DataLoader): Dataloader for the evaluation dataset.\n",
        "        num_classes (int): Number of segmentation classes.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Pixel accuracy, mean accuracy, mean IoU, and frequency-weighted IoU.\n",
        "    \"\"\"\n",
        "    evaluator = Evaluator(num_classes)\n",
        "\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            evaluator.add_batch(labels.cpu().numpy(), preds.cpu().numpy())\n",
        "\n",
        "    pixel_accuracy = evaluator.Pixel_Accuracy()\n",
        "    mean_accuracy = evaluator.Pixel_Accuracy_Class()\n",
        "    mean_IoU = evaluator.Mean_Intersection_over_Union()\n",
        "    frequency_weighted_IoU = evaluator.Frequency_Weighted_Intersection_over_Union()\n",
        "\n",
        "    return pixel_accuracy, mean_accuracy, mean_IoU, frequency_weighted_IoU"
      ],
      "metadata": {
        "id": "oT7hSNI2TDdh"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Applying the epochIterator"
      ],
      "metadata": {
        "id": "fniKkzFPumX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    train_epoch_loss = train(train_loader, model, optimizer, criterion, device)\n",
        "    val_epoch_loss = validate(val_loader, model, criterion, device)\n",
        "    train_loss.append(train_epoch_loss)\n",
        "    val_loss.append(val_epoch_loss)\n",
        "    scheduler.step()\n",
        "    print(f\"Training Loss: {train_epoch_loss:.4f} | Validation Loss: {val_epoch_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDGR8791uIMb",
        "outputId": "233bab00-e3b7-4017-fee0-d41b69d7fcf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load evaluation method for model evaluation."
      ],
      "metadata": {
        "id": "1B8fCxW6TQzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model's accuracy\n",
        "pixel_accuracy, mean_accuracy, mean_IoU, frequency_weighted_IoU = do_accuracy_evaluation(model, val_loader, num_classes)\n",
        "\n",
        "# Display the evaluation metrics results\n",
        "print(f\"Pixel Accuracy: {pixel_accuracy:.4f}\")\n",
        "print(f\"Mean Accuracy: {mean_accuracy:.4f}\")\n",
        "print(f\"Mean IoU: {mean_IoU:.4f}\")\n",
        "print(f\"Frequency Weighted IoU: {frequency_weighted_IoU:.4f}\")"
      ],
      "metadata": {
        "id": "bWMvu-L3TQHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Results"
      ],
      "metadata": {
        "id": "eCeeasyoTf_m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8.1 Method to plot prediction"
      ],
      "metadata": {
        "id": "fKBsnpZ7TnRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to visualize predictions\n",
        "def plot_predictions(model, data_loader, device, num_images=5):\n",
        "    \"\"\"Visualize predictions from the model compared to ground truth labels.\n",
        "\n",
        "    Parameters:\n",
        "        model (torch.nn.Module): Trained model for segmentation.\n",
        "        data_loader (torch.utils.data.DataLoader): DataLoader for the dataset.\n",
        "        device (torch.device): Device onde o modelo est rodando.\n",
        "        num_images (int): Nmero de imagens para visualizar.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    images_displayed = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            # Move data back to CPU for visualization\n",
        "            images = images.cpu()\n",
        "            labels = labels.cpu()\n",
        "            preds = preds.cpu()\n",
        "\n",
        "            # Visualize predictions compared to ground truth\n",
        "            for i in range(min(num_images, len(images))):\n",
        "                fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "                # Select only three channels for display or compute mean\n",
        "                image_display = images[i, :3].permute(1, 2, 0)  # Consider only the first 3 channels\n",
        "\n",
        "                axs[0].imshow(image_display)\n",
        "                axs[0].set_title(\"Input Image\")\n",
        "                axs[1].imshow(labels[i], cmap=\"gray\")\n",
        "                axs[1].set_title(\"Ground Truth\")\n",
        "                axs[2].imshow(preds[i], cmap=\"gray\")\n",
        "                axs[2].set_title(\"Prediction\")\n",
        "                plt.show()\n",
        "\n",
        "                images_displayed += 1\n",
        "                if images_displayed >= num_images:\n",
        "                    return\n",
        "\n"
      ],
      "metadata": {
        "id": "hOBo_6u-TkoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot predictions"
      ],
      "metadata": {
        "id": "hg7QzuUKUAcE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize predictions\n",
        "plot_predictions(model, val_loader, device, num_images=5)"
      ],
      "metadata": {
        "id": "srMy7nGmUFWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2 Save trained model"
      ],
      "metadata": {
        "id": "q94CT1SFULFI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the trained model's state dict\n",
        "model_path = \"/content/gdrive/My Drive/adleo_my/final_project/resunet_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved to {model_path}\")"
      ],
      "metadata": {
        "id": "r7Bd_kHyUJ2W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}