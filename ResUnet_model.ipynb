{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV-cucBR_Oa8"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEtSe9mC9C-y"
      },
      "source": [
        "# **Load the libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDHH7U_yg5yE",
        "outputId": "dacfcc42-eb05-4d81-f5b7-19a55f932e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rasterio\n",
            "  Downloading rasterio-1.3.10-cp310-cp310-manylinux2014_x86_64.whl (21.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.5/21.5 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting affine (from rasterio)\n",
            "  Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from rasterio) (23.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from rasterio) (2024.2.2)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.10/dist-packages (from rasterio) (8.1.7)\n",
            "Requirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.10/dist-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.25.2)\n",
            "Collecting snuggs>=1.4.1 (from rasterio)\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: click-plugins in /usr/local/lib/python3.10/dist-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from rasterio) (67.7.2)\n",
            "Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.10/dist-packages (from snuggs>=1.4.1->rasterio) (3.1.2)\n",
            "Installing collected packages: snuggs, affine, rasterio\n",
            "Successfully installed affine-2.4.0 rasterio-1.3.10 snuggs-1.4.7\n"
          ]
        }
      ],
      "source": [
        "# Import essential libraries for deep learning and data handling\n",
        "import os\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "from google.colab import drive\n",
        "\n",
        "# Libraries for image handling and visualization\n",
        "!pip install rasterio\n",
        "import matplotlib.pyplot as plt\n",
        "import rasterio\n",
        "from rasterio.windows import Window\n",
        "\n",
        "# Additional utilities\n",
        "import logging\n",
        "import tqdm\n",
        "from datetime import datetime\n",
        "import itertools\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3wdtTp2-C-i"
      },
      "source": [
        "# **Setup and Data Path Configuration for Colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfKc_fG3-BFu",
        "outputId": "65e1e59a-2664-480c-a32b-edf66ebaf73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Setup for mounting Google Drive in Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Directory where the data is stored\n",
        "data_dir = \"/content/gdrive/My Drive/adleo_my/final_project/data/\"\n",
        "\n",
        "# Paths to images, labels, and catalog\n",
        "image_paths = list(Path(data_dir).glob(\"images/*.tif\"))\n",
        "label_paths = list(Path(data_dir).glob(\"labels/*.tif\"))\n",
        "catalog_paths = \"/content/gdrive/MyDrive/adleo_my/final_project/data/label-catalog-filtered.csv\"\n",
        "\n",
        "# Ensure that paths are sorted and matched\n",
        "image_paths.sort()\n",
        "label_paths.sort()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwQpFa7oebhQ"
      },
      "source": [
        "## **Step 1: Definition of the ResUNet Architecture**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "9yPYDX1VeTHZ"
      },
      "outputs": [],
      "source": [
        "# Residual Block Class\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, downsample=None, upsample=None):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.upsample = upsample\n",
        "        stride = 2 if downsample else 1\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Adjust the shortcut to match dimensions\n",
        "        if in_channels != out_channels or downsample:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "        else:\n",
        "            self.shortcut = nn.Identity()\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = self.shortcut(x)\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.upsample and out.size() != identity.size():\n",
        "            identity = F.interpolate(identity, size=out.shape[2:], mode='bilinear', align_corners=False)\n",
        "\n",
        "        out += identity\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "class ResUNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResUNet, self).__init__()\n",
        "        self.encoder1 = ResBlock(in_channels, 64)\n",
        "        self.encoder2 = ResBlock(64, 128, downsample=True)\n",
        "        self.encoder3 = ResBlock(128, 256, downsample=True)\n",
        "        self.encoder4 = ResBlock(256, 512, downsample=True)\n",
        "\n",
        "        self.decoder1 = ResBlock(512, 256, upsample=True)\n",
        "        self.decoder2 = ResBlock(256, 128, upsample=True)\n",
        "        self.decoder3 = ResBlock(128, 64, upsample=True)\n",
        "        self.decoder4 = ResBlock(64, out_channels, upsample=True)\n",
        "\n",
        "        self.final_conv = nn.Conv2d(out_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        e1 = self.encoder1(x)\n",
        "        e2 = self.encoder2(e1)\n",
        "        e3 = self.encoder3(e2)\n",
        "        e4 = self.encoder4(e3)\n",
        "\n",
        "        d1 = self.decoder1(e4)\n",
        "        d2 = self.decoder2(F.interpolate(d1, scale_factor=2) + e3)  # Ensure dimension match\n",
        "        d3 = self.decoder3(F.interpolate(d2, scale_factor=2) + e2)  # Ensure dimension match\n",
        "        d4 = self.decoder4(F.interpolate(d3, scale_factor=2) + e1)  # Ensure dimension match\n",
        "\n",
        "        out = self.final_conv(d4)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiMN7h94evnP"
      },
      "source": [
        "## **Step 2: Utility Functions for Data Handling in Satellite Image Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MM2v6q33e2ba"
      },
      "outputs": [],
      "source": [
        "# Utility function to load image data\n",
        "def load_data(filepath, is_label=False):\n",
        "    \"\"\"Loads image data from a file using rasterio, with option to load as label data.\"\"\"\n",
        "    with rasterio.open(filepath) as src:\n",
        "        if is_label:\n",
        "            # For labels, assume single channel and integer type\n",
        "            data = src.read(1)  # read the first channel\n",
        "        else:\n",
        "            # For images, read all bands\n",
        "            data = src.read()\n",
        "\n",
        "        # Convert data to float32 and scale to [0, 1]\n",
        "        if not is_label:\n",
        "            data = data.astype(np.float32)\n",
        "            data /= 255.0\n",
        "\n",
        "    return torch.from_numpy(data)\n",
        "\n",
        "# Function to normalize image data\n",
        "def normalize_data(image, mean, std):\n",
        "    \"\"\"Normalize image data using provided mean and standard deviation.\"\"\"\n",
        "    if image.ndim == 3:  # if image has multiple channels\n",
        "        for i in range(image.shape[0]):  # normalize each channel\n",
        "            image[i, :, :] = (image[i, :, :] - mean[i]) / std[i]\n",
        "    else:  # if single channel (e.g., label or grayscale image)\n",
        "        image = (image - mean) / std\n",
        "    return image\n",
        "\n",
        "# Function to apply transformations to dataset (augmentation)\n",
        "def transform(image, label):\n",
        "    \"\"\"Apply transformations to the image and label for data augmentation.\"\"\"\n",
        "    # Example transformation: vertical flip\n",
        "    if torch.rand(1) > 0.5:\n",
        "        image = torch.flip(image, [1])  # flip along vertical axis\n",
        "        label = torch.flip(label, [1])  # flip along vertical axis\n",
        "    return image, label\n",
        "\n",
        "# Function to get windows of data from large images\n",
        "def get_data_window(data, row_start, row_end, col_start, col_end):\n",
        "    \"\"\"Extract a window of data from a larger array.\"\"\"\n",
        "    return data[:, row_start:row_end, col_start:col_end]\n",
        "\n",
        "# Example use within a dataset class\n",
        "class SatelliteImageDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Dataset class for satellite images, utilizing the utility functions above.\"\"\"\n",
        "    def __init__(self, image_paths, label_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label_path = self.label_paths[idx]\n",
        "\n",
        "        image = load_data(image_path)\n",
        "        label = load_data(label_path, is_label=True)\n",
        "\n",
        "        if self.transform:\n",
        "            image, label = self.transform(image, label)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K749tMg9-Q_2"
      },
      "source": [
        "## **Step 3: Data Preparation and Transformation Setup for Image Processing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "V7vMWQene-XV"
      },
      "outputs": [],
      "source": [
        "# Adjust normalization to handle images that may have an extra channel\n",
        "class Normalize(transforms.Normalize):\n",
        "    \"\"\"Normalize only the first three channels of the image.\"\"\"\n",
        "    def __call__(self, tensor):\n",
        "        if tensor.size(0) == 4:\n",
        "            tensor[:3] = super().__call__(tensor[:3])\n",
        "            return tensor\n",
        "        return super().__call__(tensor)\n",
        "\n",
        "# Define transformations for images (assuming these are RGB images)\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define transformations for labels (if these are masks, just convert to tensor)\n",
        "label_transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, image_paths, label_paths, image_transform=None, label_transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.label_paths = label_paths\n",
        "        self.image_transform = image_transform\n",
        "        self.label_transform = label_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        # Ensuring the length function does not cause an index out of range\n",
        "        return min(len(self.image_paths), len(self.label_paths))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if index >= len(self.image_paths) or index >= len(self.label_paths):\n",
        "            raise IndexError(\"Index {} is out of range\".format(index))\n",
        "\n",
        "        image_path = self.image_paths[index]\n",
        "        label_path = self.label_paths[index]\n",
        "\n",
        "        try:\n",
        "            with rasterio.open(image_path) as src:\n",
        "                image = src.read().astype('float32')\n",
        "            with rasterio.open(label_path) as src:\n",
        "                label = src.read(1).astype('float32')\n",
        "        except Exception as e:\n",
        "            raise RuntimeError(\"Error opening image files at index {}: {}\".format(index, e))\n",
        "\n",
        "        # Ensure the image is three channels (RGB)\n",
        "        if image.shape[0] == 1:\n",
        "            image = np.tile(image, (3, 1, 1))  # Duplicate the single channel to make it three channels\n",
        "        elif image.shape[0] > 3:\n",
        "            image = image[:3, :, :]  # Use only the first three channels if there are more\n",
        "\n",
        "        image = np.transpose(image, (1, 2, 0))  # CHW to HWC for torchvision transforms\n",
        "\n",
        "        if self.image_transform:\n",
        "            image = self.image_transform(image)\n",
        "        if self.label_transform:\n",
        "            label = self.label_transform(label)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Assume image_transform and label_transform are defined elsewhere:\n",
        "image_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "label_transform = transforms.ToTensor()\n",
        "\n",
        "# Example usage:\n",
        "train_dataset = CustomDataset(image_paths, label_paths, image_transform, label_transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
        "val_dataset = CustomDataset(image_paths, label_paths, image_transform, label_transform)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0l2RDdpWfPOw"
      },
      "source": [
        "## **Step 4: Model Training Setup and Execution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fVYPPa9Ufw5f"
      },
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "learning_rate = 0.001\n",
        "batch_size = 16\n",
        "epochs = 1\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Initialize the model\n",
        "model = ResUNet(in_channels=3, out_channels=1).to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss for binary classification tasks\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop definition\n",
        "def train_loop(dataloader, model, loss_fn, optimizer, device):\n",
        "    \"\"\"Function to execute the training loop.\"\"\"\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch, (images, labels) in enumerate(dataloader):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass: Compute predictions and loss\n",
        "        preds = model(images)\n",
        "        loss = loss_fn(preds, labels)\n",
        "\n",
        "        # Backward pass: Compute gradient and do optimizer step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Print loss every 100 batches\n",
        "        if batch % 100 == 0:\n",
        "            current_loss = total_loss / (batch + 1)\n",
        "            print(f\"Batch {batch}, Loss: {current_loss:.4f}\")\n",
        "\n",
        "# Validation loop definition\n",
        "def validate_loop(dataloader, model, loss_fn, device):\n",
        "    \"\"\"Function to execute the validation loop.\"\"\"\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            preds = model(images)\n",
        "            loss = loss_fn(preds, labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Validation Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAw-WYFFgFw7"
      },
      "source": [
        "## **Step 5: Model Training and Validation Execution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnJnH1EKgH-y",
        "outputId": "5979df0c-8538-4471-fd20-fa79cb38f384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1 -------------------------------\n",
            "Batch 0, Loss: 0.7018\n",
            "Batch 100, Loss: 0.7021\n",
            "Batch 200, Loss: 0.7020\n"
          ]
        }
      ],
      "source": [
        "# Execute training and validation\n",
        "def run_training(train_loader, val_loader, model, loss_fn, optimizer, epochs, device):\n",
        "    \"\"\"Executes the training and validation process over a given number of epochs.\"\"\"\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"Epoch {epoch+1}/{epochs} -------------------------------\")\n",
        "\n",
        "        # Train the model for one epoch\n",
        "        train_loop(train_loader, model, loss_fn, optimizer, device)\n",
        "\n",
        "        # Validate the model at the end of the epoch\n",
        "        validate_loop(val_loader, model, loss_fn, device)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "# Save the trained model\n",
        "def save_model(model, path):\n",
        "    \"\"\"Saves the model to the specified path.\"\"\"\n",
        "    torch.save(model.state_dict(), path)\n",
        "    print(f\"Model saved to {path}\")\n",
        "\n",
        "# Setup data loaders (assuming train_loader and val_loader are already defined)\n",
        "\n",
        "# Paths for saving the model\n",
        "model_save_path = \"/content/gdrive/My Drive/trained_resunet.pth\"\n",
        "\n",
        "# Running the training and validation\n",
        "run_training(train_loader, val_loader, model, criterion, optimizer, epochs, device)\n",
        "\n",
        "# Saving the trained model\n",
        "save_model(model, model_save_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}